# Script Evaluation through AI

An AI-Based Script Evaluation System that automates the assessment of descriptive answer scripts using Optical Character Recognition (OCR) and Natural Language Processing (NLP).

---

## ğŸ“Œ Project Overview

Manual evaluation of descriptive answer scripts is time-consuming, subjective, and prone to inconsistencies.  
This project provides an AI-assisted solution that helps teachers evaluate answer scripts efficiently while maintaining fairness and transparency.

The system extracts text from scanned answer scripts, segments answers question-wise, evaluates responses using semantic similarity, and generates explainable feedback. Teacher validation is supported to ensure reliability.

---

## ğŸ¯ Objectives

- Automate evaluation of descriptive answer scripts  
- Reduce manual correction effort for teachers  
- Provide consistent and explainable scoring  
- Compare AI-generated scores with teacher scores  
- Generate detailed feedback and reports  

---

## ğŸ› ï¸ Technologies Used

- **Programming Language:** Python  
- **Backend Framework:** FastAPI  
- **OCR Engines:** Tesseract OCR, EasyOCR  
- **NLP Models:** Sentence Transformers  
- **Database:** PostgreSQL  
- **Authentication:** JWT  
- **Version Control:** Git & GitHub  

---

## âš™ï¸ System Workflow

1. Upload scanned answer scripts (PDF/Image)  
2. Extract text using OCR  
3. Segment answers using predefined question schema  
4. Perform NLP-based semantic evaluation  
5. Generate AI scores and error rates  
6. Compare with teacher-assigned marks  
7. Generate feedback and evaluation reports  

---

## ğŸ§  Methodology

- Multi-engine OCR for accurate text extraction  
- Schema-driven question-wise segmentation  
- Semantic similarity using sentence embeddings  
- Cosine similarity for scoring  
- Teacher-in-the-loop validation for reliability  

---

## ğŸ“Š Results

- Accurate evaluation of descriptive answers  
- Reduced evaluation time compared to manual correction  
- AI scores closely aligned with teacher scores  
- Meaningful feedback generated for students  

---

## ğŸ”® Future Enhancements

- Improved handwritten OCR accuracy  
- Multilingual answer script support  
- Adaptive scoring using teacher feedback  
- LMS integration  
- Plagiarism detection and analytics  

---

<img width="824" height="408" alt="image" src="https://github.com/user-attachments/assets/05605716-afaa-43e5-af7f-c9594616dc94" />


---

## ğŸ‘©â€ğŸ« Use Case

This system acts as a **decision-support tool for teachers**, not a replacement.  
Final evaluation authority remains with the educator.

---

## ğŸ“ Repository

GitHub Link:  
https://github.com/Vimuktha-coder/Script-Evaluation-through-AI

---

## âœ¨ Author

**Vimuktha**  
Final Year Major Project  
AI-Based Script Evaluation System

<img width="900" height="500" alt="image" src="https://github.com/user-attachments/assets/e673cbaa-6f6d-4516-88ef-217d4c335ddf" />


<img width="800" height="600" alt="image" src="https://github.com/user-attachments/assets/193b27e2-bdfd-40ed-b4af-2b6be9762979" />


